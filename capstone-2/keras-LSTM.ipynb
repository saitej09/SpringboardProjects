{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported libs ..!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from tensorflow.python.keras.utils import np_utils\n",
    "# from tensorflow.python.keras.models import *\n",
    "# from tensorflow.python.keras.layers import *\n",
    "# from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.python.keras import regularizers\n",
    "# from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "print(\"imported libs ..!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('tweet-sentiment-extraction-data/train.csv')\n",
    "test = pd.read_csv('tweet-sentiment-extraction-data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(axis=0, how='any', inplace=True)\n",
    "test.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train['text'].apply(str).values\n",
    "selected_text = train['selected_text'].apply(str).values\n",
    "sentiment = train['sentiment'].apply(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0].index(selected_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = []\n",
    "end = []\n",
    "for i in range(len(text)):\n",
    "    idx = text[i].index(selected_text[i])\n",
    "    beg.append(text[i][:idx])\n",
    "    end.append(text[i][idx+len(selected_text[i]):])\n",
    "    \n",
    "train['beg'] = beg\n",
    "train['end'] = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>I will miss you here in San Diego!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview!</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>why couldn`t they put them on the releases we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment                beg  \\\n",
       "0  I`d have responded, if I were going   neutral                      \n",
       "1                             Sooo SAD  negative                      \n",
       "2                          bullying me  negative        my boss is    \n",
       "3                       leave me alone  negative   what interview!    \n",
       "4                        Sons of ****,  negative                      \n",
       "\n",
       "                                                 end  \n",
       "0                                                     \n",
       "1               I will miss you here in San Diego!!!  \n",
       "2                                                ...  \n",
       "3                                                     \n",
       "4   why couldn`t they put them on the releases we...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknzr = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## O for outside the sel_text and Y for with in the sel text\n",
    "xt = []\n",
    "yt = []\n",
    "\n",
    "for i in range(len(train)):\n",
    "    bg = tknzr.tokenize(train.iloc[i]['beg'])\n",
    "    sel = tknzr.tokenize(train.iloc[i]['selected_text'])\n",
    "    end = tknzr.tokenize(train.iloc[i]['end'])\n",
    "    inp = bg + sel + end \n",
    "    op = [\"O\" for i in range(len(bg))] + [\"Y\" for i in range(len(sel))] + [\"O\" for i in range(len(end))]\n",
    "    xt.append(inp)\n",
    "    yt.append(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sons',\n",
       " 'of',\n",
       " '*',\n",
       " '*',\n",
       " '*',\n",
       " ',',\n",
       " 'why',\n",
       " 'couldn',\n",
       " '`',\n",
       " 't',\n",
       " 'they',\n",
       " 'put',\n",
       " 'them',\n",
       " 'on',\n",
       " 'the',\n",
       " 'releases',\n",
       " 'we',\n",
       " 'already',\n",
       " 'bought']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Y',\n",
       " 'Y',\n",
       " 'Y',\n",
       " 'Y',\n",
       " 'Y',\n",
       " 'Y',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[]\n",
    "for i in range(len(xt)):\n",
    "    words = words + xt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_words = list(set(words))\n",
    "_words = _words + ['PADDING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34208"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i for i,w in enumerate(_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apologies': 0,\n",
       " 'Filipno': 1,\n",
       " 'ftsk': 2,\n",
       " 'logins': 3,\n",
       " 'Happens': 4,\n",
       " 'meeting': 5,\n",
       " 'damage': 6,\n",
       " 'fanclub': 7,\n",
       " 'Lily': 8,\n",
       " 'waah': 9,\n",
       " 'Mattew': 10,\n",
       " '_Von_Abe': 11,\n",
       " 'nomes': 12,\n",
       " 'australia': 13,\n",
       " 'alabang': 14,\n",
       " 'Bose': 15,\n",
       " '#Migraines': 16,\n",
       " 'http://tr.im/kWnX': 17,\n",
       " 'gots': 18,\n",
       " 'apathy': 19,\n",
       " 'seems': 20,\n",
       " 'Youtube': 21,\n",
       " 'bedd': 22,\n",
       " 'sticks': 23,\n",
       " 'enlgland': 24,\n",
       " 'nw': 25,\n",
       " 'Lin-Man': 26,\n",
       " 'charades': 27,\n",
       " 'ikea': 28,\n",
       " 'bk': 29,\n",
       " 'Bff': 30,\n",
       " 'creep': 31,\n",
       " 'Superstar': 32,\n",
       " 'delhi': 33,\n",
       " 'http://bit.ly/NgnaR': 34,\n",
       " 'yeha': 35,\n",
       " 'arlington': 36,\n",
       " 'cherry': 37,\n",
       " 'bklyn': 38,\n",
       " '_Ross': 39,\n",
       " 'pigment': 40,\n",
       " 'America': 41,\n",
       " 'splinters': 42,\n",
       " 'approving': 43,\n",
       " 'IRON': 44,\n",
       " 'widget': 45,\n",
       " 'Gloomy': 46,\n",
       " 'lovies': 47,\n",
       " 'Stress-free': 48,\n",
       " 'hundred': 49,\n",
       " 'Sore': 50,\n",
       " 'coFFee': 51,\n",
       " 'movieee': 52,\n",
       " 'TWO': 53,\n",
       " 'turkish': 54,\n",
       " 'uit': 55,\n",
       " 'skwl': 56,\n",
       " 'operational': 57,\n",
       " 'creche': 58,\n",
       " 'Teflon': 59,\n",
       " 'burns': 60,\n",
       " 'Welcome': 61,\n",
       " 'FINALY': 62,\n",
       " 'buying': 63,\n",
       " 'expert': 64,\n",
       " 'rly': 65,\n",
       " 'nEEd': 66,\n",
       " 'avid': 67,\n",
       " 'Southridge': 68,\n",
       " 'pokes': 69,\n",
       " 'Heaven.fr': 70,\n",
       " 'ohbabayy': 71,\n",
       " 'lays': 72,\n",
       " 'NE': 73,\n",
       " 'divorcing': 74,\n",
       " 'http://bit.ly/18aEG8': 75,\n",
       " 'nosely': 76,\n",
       " 'isnï': 77,\n",
       " 'Trans-Siberian': 78,\n",
       " 'disconnected': 79,\n",
       " 'Company': 80,\n",
       " 'magazines': 81,\n",
       " 'MusiCares': 82,\n",
       " 'YourBiggestFan': 83,\n",
       " 'boost': 84,\n",
       " 'shudve': 85,\n",
       " 'Chilis': 86,\n",
       " 'touched': 87,\n",
       " 'kathryn': 88,\n",
       " 'Interesting': 89,\n",
       " 'beastypops': 90,\n",
       " 'occasionally': 91,\n",
       " 'ravey': 92,\n",
       " '_Bee': 93,\n",
       " 'Kinda': 94,\n",
       " 'ty': 95,\n",
       " 'Cavalcade': 96,\n",
       " 'RACE': 97,\n",
       " 'rumor': 98,\n",
       " 'appartement': 99,\n",
       " 'hari': 100,\n",
       " 'WEEKDAYS': 101,\n",
       " 'Without': 102,\n",
       " 'Crawfish': 103,\n",
       " 'Antonio': 104,\n",
       " 'blockhead': 105,\n",
       " 'messenger': 106,\n",
       " 'PFFT': 107,\n",
       " 'http://plurk.com/p/rpaag': 108,\n",
       " 'freezing': 109,\n",
       " 'ubuntu': 110,\n",
       " 'starburst': 111,\n",
       " 'satrted': 112,\n",
       " 'uninhabital': 113,\n",
       " '14mph': 114,\n",
       " 'Scrubs': 115,\n",
       " 'rul': 116,\n",
       " 'Cingular': 117,\n",
       " 'J': 118,\n",
       " 'cu': 119,\n",
       " 'more': 120,\n",
       " 'stupidstupid': 121,\n",
       " '... ... ...': 122,\n",
       " 'TSi': 123,\n",
       " 'mhmm': 124,\n",
       " 'moolah': 125,\n",
       " 'Laker': 126,\n",
       " 'SCIENCE': 127,\n",
       " 'HSG': 128,\n",
       " '3-2': 129,\n",
       " 'omnia': 130,\n",
       " 'http://bit.ly/gihac': 131,\n",
       " 'Moral': 132,\n",
       " 'gridiron': 133,\n",
       " 'Peaks': 134,\n",
       " 'Members': 135,\n",
       " 'migh': 136,\n",
       " 'journal': 137,\n",
       " 'COME': 138,\n",
       " 'Puts': 139,\n",
       " 'laid': 140,\n",
       " 'muah': 141,\n",
       " 'jail': 142,\n",
       " '167': 143,\n",
       " 'tortoiseshell': 144,\n",
       " 'ritualistic': 145,\n",
       " 'Learned': 146,\n",
       " '_01': 147,\n",
       " 'swine': 148,\n",
       " 'BIF': 149,\n",
       " 'xox': 150,\n",
       " 'Yoplait': 151,\n",
       " 'shannen': 152,\n",
       " 'goodnights': 153,\n",
       " 'Zen-related': 154,\n",
       " 'uritors': 155,\n",
       " '3lbs': 156,\n",
       " 'amateur': 157,\n",
       " 'impatient': 158,\n",
       " 'tempted': 159,\n",
       " 'Burrough': 160,\n",
       " 'define': 161,\n",
       " 'Hehe': 162,\n",
       " '#tweetu': 163,\n",
       " 'Tussaud': 164,\n",
       " 'convinced': 165,\n",
       " 'cafes': 166,\n",
       " 'unknown': 167,\n",
       " 'Christ': 168,\n",
       " 'chill': 169,\n",
       " 'depresses': 170,\n",
       " 'Fab': 171,\n",
       " 'peace.love': 172,\n",
       " 'attics': 173,\n",
       " 'hungryyyyyyy': 174,\n",
       " 'tonsillitis': 175,\n",
       " '28th': 176,\n",
       " 'foster': 177,\n",
       " 'IPA': 178,\n",
       " 'swizzy': 179,\n",
       " 'waT': 180,\n",
       " 'ideas': 181,\n",
       " 'Kisses': 182,\n",
       " 'Tutle': 183,\n",
       " 'IIII': 184,\n",
       " 'http://www.vine.net/default.aspx': 185,\n",
       " '3.5': 186,\n",
       " 'plucked': 187,\n",
       " 'endometriosis': 188,\n",
       " 'marshmallows': 189,\n",
       " 'Combination': 190,\n",
       " 'Iiight': 191,\n",
       " 'genius': 192,\n",
       " 'shineeeee': 193,\n",
       " 'BEST': 194,\n",
       " 'toasters': 195,\n",
       " 'nick': 196,\n",
       " 'backroom': 197,\n",
       " 'Fukn': 198,\n",
       " 'distraught': 199,\n",
       " 'fishys': 200,\n",
       " 'commission': 201,\n",
       " 'tiny': 202,\n",
       " 'romans': 203,\n",
       " 'http://yfrog.com/097dfj': 204,\n",
       " 'future': 205,\n",
       " 'moon-day': 206,\n",
       " 'eachother': 207,\n",
       " 'route': 208,\n",
       " 'strict': 209,\n",
       " 'CCP': 210,\n",
       " 'http://tinyurl.com/c8fr3e': 211,\n",
       " 'oramarecords.com': 212,\n",
       " 'noble': 213,\n",
       " 'casualties': 214,\n",
       " 'caitlin': 215,\n",
       " 'quarantined': 216,\n",
       " 'HAHAHA': 217,\n",
       " 'Nooooooo': 218,\n",
       " 'roommates': 219,\n",
       " 'serious.its': 220,\n",
       " 'Way': 221,\n",
       " 'Superb': 222,\n",
       " 'recyle': 223,\n",
       " 'everrrrr': 224,\n",
       " 'interviewed': 225,\n",
       " '#TwitterTakeover': 226,\n",
       " 'OP': 227,\n",
       " 'Prez': 228,\n",
       " '1thing': 229,\n",
       " 'Abrams': 230,\n",
       " 'Kris': 231,\n",
       " '_steph': 232,\n",
       " 'costume': 233,\n",
       " 'cats': 234,\n",
       " 'deathfic': 235,\n",
       " 'Rocks': 236,\n",
       " 'tutor': 237,\n",
       " 'dissects': 238,\n",
       " 'Steak': 239,\n",
       " 'frame': 240,\n",
       " 'sway': 241,\n",
       " 'cerritos': 242,\n",
       " 'hound': 243,\n",
       " 'eens': 244,\n",
       " 'Marlees': 245,\n",
       " 'TINK': 246,\n",
       " 'teens': 247,\n",
       " 'detect': 248,\n",
       " 'iTouch': 249,\n",
       " 'seventh': 250,\n",
       " 'projection': 251,\n",
       " 'subbed': 252,\n",
       " 'impression': 253,\n",
       " 'tid': 254,\n",
       " 'Can': 255,\n",
       " 'spelling': 256,\n",
       " 'http://tinyurl.com/cumqmv': 257,\n",
       " 'lodging': 258,\n",
       " '9000': 259,\n",
       " 'benerin': 260,\n",
       " 'maxxie': 261,\n",
       " 'drip': 262,\n",
       " '11.02': 263,\n",
       " 'grandmother': 264,\n",
       " 'Casino': 265,\n",
       " 'fizz': 266,\n",
       " 'fireflies': 267,\n",
       " 'crucial': 268,\n",
       " 'College': 269,\n",
       " 'smartpen': 270,\n",
       " 'pmsl': 271,\n",
       " 'noting': 272,\n",
       " 'mcfox': 273,\n",
       " 'http://twitpic.com/4jhp8': 274,\n",
       " 'tiiiiiiired': 275,\n",
       " 'lead': 276,\n",
       " '@_enzo': 277,\n",
       " 'http://bit.ly/Fle9j': 278,\n",
       " 'tunnel': 279,\n",
       " '5/3': 280,\n",
       " '_Dreaming': 281,\n",
       " 'flavor': 282,\n",
       " 'dumb': 283,\n",
       " 'Aaaargh': 284,\n",
       " 'kleine': 285,\n",
       " 'Traditional': 286,\n",
       " 'Botcon': 287,\n",
       " 'excercise': 288,\n",
       " 'replies': 289,\n",
       " 'NAPLAN': 290,\n",
       " 'leaked': 291,\n",
       " 'Pizza': 292,\n",
       " 'thighs': 293,\n",
       " 'reconize': 294,\n",
       " '½ng': 295,\n",
       " 'iCal': 296,\n",
       " 'Todays': 297,\n",
       " '#celtics': 298,\n",
       " 'Zac': 299,\n",
       " 'Everybody': 300,\n",
       " 'fall': 301,\n",
       " 'charity': 302,\n",
       " 'Gizmo': 303,\n",
       " 'PCD': 304,\n",
       " 'accidently': 305,\n",
       " 'slackin': 306,\n",
       " 'Repeatedly': 307,\n",
       " 'Spending': 308,\n",
       " 'Mc': 309,\n",
       " 'cliffs': 310,\n",
       " 'bun.Yum': 311,\n",
       " '7.53': 312,\n",
       " 'likes': 313,\n",
       " 'St': 314,\n",
       " 'log': 315,\n",
       " 'tisk': 316,\n",
       " 'Daaay': 317,\n",
       " 'do': 318,\n",
       " 'embouchure': 319,\n",
       " 'annoy': 320,\n",
       " '1B': 321,\n",
       " 'doggie': 322,\n",
       " 'capitan': 323,\n",
       " 'mart': 324,\n",
       " 'HER': 325,\n",
       " 'necklace': 326,\n",
       " 'panicky': 327,\n",
       " 'Idol': 328,\n",
       " 'MINE': 329,\n",
       " 'DOS': 330,\n",
       " 'B2G1': 331,\n",
       " 'selling': 332,\n",
       " 'Woody': 333,\n",
       " 'Seriously': 334,\n",
       " '71': 335,\n",
       " 'TLC': 336,\n",
       " 'f1': 337,\n",
       " 'toinks': 338,\n",
       " 'Grinding': 339,\n",
       " 'Applying': 340,\n",
       " 'Dane': 341,\n",
       " 'mini-itx': 342,\n",
       " 'todayyy': 343,\n",
       " 'cleavage': 344,\n",
       " 'Bloody': 345,\n",
       " 'espressos': 346,\n",
       " 'Polly': 347,\n",
       " 'healthcare': 348,\n",
       " 'SY': 349,\n",
       " 'lid': 350,\n",
       " 'wardrobe': 351,\n",
       " 'nita': 352,\n",
       " 'recolouring': 353,\n",
       " 'broth': 354,\n",
       " 'Faire': 355,\n",
       " 'mayyyybe': 356,\n",
       " 'http://bit.ly/1doE': 357,\n",
       " 'doberman': 358,\n",
       " 'prayers': 359,\n",
       " 'sendi': 360,\n",
       " 'SHALL': 361,\n",
       " 'gardens': 362,\n",
       " 'bbff': 363,\n",
       " 'togeth': 364,\n",
       " 'Doo': 365,\n",
       " 'pipe': 366,\n",
       " 'babi': 367,\n",
       " 'www.traveljunky.com': 368,\n",
       " 'http://tumblr.com/xbb1qyx0e': 369,\n",
       " 'Contern': 370,\n",
       " 'heyyyyyyyyyyyyyya': 371,\n",
       " 'Shoes': 372,\n",
       " 'ideia': 373,\n",
       " 'lampions': 374,\n",
       " 'whatta': 375,\n",
       " 'yEssss': 376,\n",
       " 'toast': 377,\n",
       " '_M': 378,\n",
       " 'installed': 379,\n",
       " 'court': 380,\n",
       " 'panhandlers': 381,\n",
       " 'Reg': 382,\n",
       " 'division': 383,\n",
       " 'sukks': 384,\n",
       " 'TMobile': 385,\n",
       " 'PIZZA': 386,\n",
       " 'neeeddd': 387,\n",
       " 'Charms': 388,\n",
       " 'rockpools': 389,\n",
       " 'Try': 390,\n",
       " 'hall': 391,\n",
       " 'festival': 392,\n",
       " 'wowzers': 393,\n",
       " 'visitor': 394,\n",
       " 'waaa': 395,\n",
       " 'planing': 396,\n",
       " 'il': 397,\n",
       " '_n_nouns': 398,\n",
       " 'itell': 399,\n",
       " 'badges': 400,\n",
       " 'config': 401,\n",
       " 'okey': 402,\n",
       " '_1999': 403,\n",
       " 'mailbox': 404,\n",
       " 'hands': 405,\n",
       " 'Analytics': 406,\n",
       " 'http://amanita-design.net/samorost-1/': 407,\n",
       " 'Polka': 408,\n",
       " 'slpy': 409,\n",
       " '_hunter': 410,\n",
       " 'Beverly': 411,\n",
       " 'lovely': 412,\n",
       " 'Returned': 413,\n",
       " 'coldplay': 414,\n",
       " 'valentines': 415,\n",
       " 'quit': 416,\n",
       " 'virge': 417,\n",
       " 'has': 418,\n",
       " 'Beto': 419,\n",
       " 'Great': 420,\n",
       " 'Goulburn': 421,\n",
       " 'supprtin': 422,\n",
       " 'www.justin.tv/kubbur?20': 423,\n",
       " 'puce': 424,\n",
       " 'WALLET': 425,\n",
       " 'blogging': 426,\n",
       " 'Olive': 427,\n",
       " 'answerer': 428,\n",
       " 'Union': 429,\n",
       " 'sooooo': 430,\n",
       " 'pacing': 431,\n",
       " 'SHOCK': 432,\n",
       " 'scribe': 433,\n",
       " 'Laundry': 434,\n",
       " 'buzy': 435,\n",
       " 'goo': 436,\n",
       " 'night.They': 437,\n",
       " 'Mocha': 438,\n",
       " 'Darrius': 439,\n",
       " 'FAKING': 440,\n",
       " '6:15': 441,\n",
       " 'freezer': 442,\n",
       " 'Gas-x': 443,\n",
       " '27': 444,\n",
       " 'bacardi': 445,\n",
       " 'doom': 446,\n",
       " 'Hallooo': 447,\n",
       " 'Rachel': 448,\n",
       " 'driver': 449,\n",
       " '_beli': 450,\n",
       " '@_josh_thomas': 451,\n",
       " 'Heyya': 452,\n",
       " 'Depot': 453,\n",
       " 'tuning': 454,\n",
       " 'elbow': 455,\n",
       " 'AWWWW': 456,\n",
       " 'productive': 457,\n",
       " 'Growing': 458,\n",
       " 'howre': 459,\n",
       " 'gandhi': 460,\n",
       " 'wrong': 461,\n",
       " 'FL': 462,\n",
       " 'Heavy': 463,\n",
       " 'harrassment': 464,\n",
       " 'laffy': 465,\n",
       " 'cud': 466,\n",
       " 'ANOTHER': 467,\n",
       " 'Lessons': 468,\n",
       " 'wide': 469,\n",
       " 'nicely': 470,\n",
       " 'Emilie': 471,\n",
       " 'http://yfrog.com/104m6wj': 472,\n",
       " 'http://twitpic.com/336u5': 473,\n",
       " 'Darnit': 474,\n",
       " 'minimum': 475,\n",
       " 'generalisations': 476,\n",
       " 'welt': 477,\n",
       " 'clearing': 478,\n",
       " 'concentration': 479,\n",
       " 'technically': 480,\n",
       " 'tossin': 481,\n",
       " 'finding': 482,\n",
       " 'on': 483,\n",
       " '½l': 484,\n",
       " 'jkin': 485,\n",
       " 'accessible': 486,\n",
       " 'pudding': 487,\n",
       " 'LANTE': 488,\n",
       " 'pisssing': 489,\n",
       " 'fourth-grade': 490,\n",
       " 'dries': 491,\n",
       " ':-P': 492,\n",
       " 'browsers': 493,\n",
       " 'weren': 494,\n",
       " 'wasps': 495,\n",
       " 'http://tinyurl.com/dde2v6': 496,\n",
       " 'vending': 497,\n",
       " 'srsly': 498,\n",
       " 'vegetables': 499,\n",
       " 'weatherrrrr': 500,\n",
       " 'snl': 501,\n",
       " 'mascara': 502,\n",
       " '_kat': 503,\n",
       " 'overstressed': 504,\n",
       " 'fence': 505,\n",
       " 'otherdad': 506,\n",
       " 'BTW': 507,\n",
       " 'bred': 508,\n",
       " 'curses': 509,\n",
       " 'spaghetti-strap': 510,\n",
       " 'Carl': 511,\n",
       " 'http://tr.im/kpoR': 512,\n",
       " 'Noor': 513,\n",
       " '4gb': 514,\n",
       " 'Something': 515,\n",
       " '1,116': 516,\n",
       " 'foodland': 517,\n",
       " 'mayfield': 518,\n",
       " 'SKIING': 519,\n",
       " 'Leica': 520,\n",
       " 'Partyyyy': 521,\n",
       " 'Mad': 522,\n",
       " '#badmicrosoft': 523,\n",
       " 'idea': 524,\n",
       " 'umma': 525,\n",
       " 'threat': 526,\n",
       " 'Shortly': 527,\n",
       " 'innabit': 528,\n",
       " 'Sonics': 529,\n",
       " 'custody': 530,\n",
       " 'female': 531,\n",
       " 'Watir': 532,\n",
       " 'SYKES': 533,\n",
       " 'harsh': 534,\n",
       " 'tony': 535,\n",
       " 'otra': 536,\n",
       " 'mei': 537,\n",
       " 'looooong': 538,\n",
       " 'eeeeeeek': 539,\n",
       " 'November': 540,\n",
       " 'Unanticipated': 541,\n",
       " 'Colombia': 542,\n",
       " 'Outside': 543,\n",
       " 'taken': 544,\n",
       " 'Roasted': 545,\n",
       " 'http://tumblr.com/xyt1qynya': 546,\n",
       " 'indians': 547,\n",
       " 'ck': 548,\n",
       " 'Bare': 549,\n",
       " 'wont': 550,\n",
       " 'Digging': 551,\n",
       " 'yearly': 552,\n",
       " 'immboredddd': 553,\n",
       " '198': 554,\n",
       " 'pouting': 555,\n",
       " 'nks': 556,\n",
       " 'Nightss': 557,\n",
       " 'honestly': 558,\n",
       " 'direct': 559,\n",
       " 'Rescued': 560,\n",
       " '#chicago': 561,\n",
       " 'Midge': 562,\n",
       " 'explosion': 563,\n",
       " 'http://bit.ly/cUjXg': 564,\n",
       " 'Opera': 565,\n",
       " 'scotter': 566,\n",
       " 'http://bit.ly/SS6Yp': 567,\n",
       " 'brothes': 568,\n",
       " 'concepts': 569,\n",
       " 'googling': 570,\n",
       " 'omg': 571,\n",
       " 'republic': 572,\n",
       " 'http://plurk.com/p/x2jc9': 573,\n",
       " 'Lizzi': 574,\n",
       " 'reminisce': 575,\n",
       " 'Shes': 576,\n",
       " '_sb': 577,\n",
       " 'TOMORROW': 578,\n",
       " 'Buongiorno': 579,\n",
       " 'wereld': 580,\n",
       " 'escaped': 581,\n",
       " ']:': 582,\n",
       " 'librefm': 583,\n",
       " 'Fries': 584,\n",
       " 'outlook': 585,\n",
       " 'anit': 586,\n",
       " 'bonding': 587,\n",
       " 'SUSE': 588,\n",
       " 'transmission': 589,\n",
       " 'barnsley': 590,\n",
       " 'Main': 591,\n",
       " 'guilty': 592,\n",
       " 'crisps': 593,\n",
       " 'wath': 594,\n",
       " '_what_': 595,\n",
       " 'caught': 596,\n",
       " '_diaz': 597,\n",
       " '#Sotomayor': 598,\n",
       " 'geeta': 599,\n",
       " 'othaa': 600,\n",
       " 'vcr': 601,\n",
       " 'pranks': 602,\n",
       " 'organize': 603,\n",
       " 'toodaayy': 604,\n",
       " 'Kerri': 605,\n",
       " 'blanky': 606,\n",
       " 'Amazon': 607,\n",
       " 'bron': 608,\n",
       " '_123': 609,\n",
       " 'Ian': 610,\n",
       " 'RELAXING': 611,\n",
       " 'stories': 612,\n",
       " 'mak': 613,\n",
       " 'brokun': 614,\n",
       " '½1': 615,\n",
       " 'McSkillet': 616,\n",
       " 'GAWD': 617,\n",
       " 'boys': 618,\n",
       " 'Krauss': 619,\n",
       " 'DeLeon': 620,\n",
       " 'steve-o': 621,\n",
       " 'a.wish': 622,\n",
       " 'goto': 623,\n",
       " 'BOOOO': 624,\n",
       " 'holdem': 625,\n",
       " 'physique': 626,\n",
       " 'Know': 627,\n",
       " '#spymaster': 628,\n",
       " 'sheeeeittt': 629,\n",
       " 'Compute': 630,\n",
       " 'timezzz': 631,\n",
       " 'Rye': 632,\n",
       " 'SE': 633,\n",
       " 'deliver': 634,\n",
       " 'pagee': 635,\n",
       " 'Chica': 636,\n",
       " '_shediddy': 637,\n",
       " 'owww': 638,\n",
       " 'FAIR': 639,\n",
       " 'Wisdom': 640,\n",
       " 'tremendous': 641,\n",
       " 'Leo': 642,\n",
       " 'CLEARED': 643,\n",
       " 'meant': 644,\n",
       " 'yeahhhhhyaaaaaa': 645,\n",
       " 'gate': 646,\n",
       " 'wonderful': 647,\n",
       " '_ENVY': 648,\n",
       " 'KNO': 649,\n",
       " 'sod': 650,\n",
       " 'Nessa': 651,\n",
       " 'ahhhh': 652,\n",
       " '47.060': 653,\n",
       " 'Karaoke': 654,\n",
       " 'Brixton': 655,\n",
       " 'parallel': 656,\n",
       " 'Evar': 657,\n",
       " 'William': 658,\n",
       " 'twitter-copy-topify': 659,\n",
       " 'dios': 660,\n",
       " 'Programme': 661,\n",
       " 'florist': 662,\n",
       " 'ihop': 663,\n",
       " 'Leatherman': 664,\n",
       " '~': 665,\n",
       " 'itonlinelol': 666,\n",
       " 'Momma': 667,\n",
       " 'Card': 668,\n",
       " 'Striker': 669,\n",
       " 'Night': 670,\n",
       " 'Roast': 671,\n",
       " '3000': 672,\n",
       " 'avatar': 673,\n",
       " 'Cobra-Cam': 674,\n",
       " 'gland': 675,\n",
       " 'foad': 676,\n",
       " 'Midway': 677,\n",
       " 'grungy': 678,\n",
       " 'KG': 679,\n",
       " 'Spector': 680,\n",
       " 'duber': 681,\n",
       " 'FORZA': 682,\n",
       " 'Ashleycat': 683,\n",
       " 'reallly': 684,\n",
       " 'canadian': 685,\n",
       " 'ion': 686,\n",
       " 'vegetable': 687,\n",
       " 'dnt': 688,\n",
       " 'GWEG': 689,\n",
       " 'oreos': 690,\n",
       " 'Tp': 691,\n",
       " 'http://tinyurl.com/dzcpg3': 692,\n",
       " 'relaxin': 693,\n",
       " 'just': 694,\n",
       " 'Canvas': 695,\n",
       " 'POLICE': 696,\n",
       " 'Huntsville': 697,\n",
       " 'tagging': 698,\n",
       " '123': 699,\n",
       " 'bed.Then': 700,\n",
       " 'jet': 701,\n",
       " 'HUGE': 702,\n",
       " 'Okasan': 703,\n",
       " 'platform': 704,\n",
       " 'GAVE': 705,\n",
       " '17/7': 706,\n",
       " 'matthew': 707,\n",
       " 'stacie': 708,\n",
       " 'madeleines': 709,\n",
       " 'oven': 710,\n",
       " 'kanin': 711,\n",
       " 'cred': 712,\n",
       " 'groupies': 713,\n",
       " 'summit': 714,\n",
       " 'PARIS': 715,\n",
       " 'OASQR': 716,\n",
       " 'Lineup': 717,\n",
       " 'HAVEN': 718,\n",
       " 'clorox': 719,\n",
       " 'occasional': 720,\n",
       " '.': 721,\n",
       " 'point': 722,\n",
       " 'uniforms': 723,\n",
       " 'backing': 724,\n",
       " 'Dodgers': 725,\n",
       " 'cryy': 726,\n",
       " 'bongie': 727,\n",
       " 'madly': 728,\n",
       " 'eighties': 729,\n",
       " 'LaLaLand': 730,\n",
       " 'potter': 731,\n",
       " 'Come': 732,\n",
       " 'forum': 733,\n",
       " 'OLD': 734,\n",
       " 'Jarn': 735,\n",
       " 'indulge': 736,\n",
       " 'rainforest': 737,\n",
       " 'yaayy': 738,\n",
       " 'darn': 739,\n",
       " 'Alone': 740,\n",
       " 'intrusion': 741,\n",
       " 'ofÂ': 742,\n",
       " 'dinghy': 743,\n",
       " 'pasadena': 744,\n",
       " 'shampoo': 745,\n",
       " 'heheï': 746,\n",
       " 'commercials': 747,\n",
       " '_cm': 748,\n",
       " 'EVER': 749,\n",
       " 'alreay': 750,\n",
       " 'ama': 751,\n",
       " 'hhahaa': 752,\n",
       " 'beamer': 753,\n",
       " 'Wonder': 754,\n",
       " 'gprof': 755,\n",
       " 'FAM': 756,\n",
       " 'deodorant': 757,\n",
       " 'hand-make': 758,\n",
       " 'Pinkpop': 759,\n",
       " 'refunded': 760,\n",
       " '405': 761,\n",
       " 'bet': 762,\n",
       " 'lighten': 763,\n",
       " 'aston': 764,\n",
       " '_defcon1': 765,\n",
       " '@_callmeCourt': 766,\n",
       " 'webkit': 767,\n",
       " 'devs': 768,\n",
       " 'freeeeeeee': 769,\n",
       " 'Paionks': 770,\n",
       " 'http://twitpic.com/4wn29': 771,\n",
       " 'awe': 772,\n",
       " '_ryan': 773,\n",
       " 'retail': 774,\n",
       " 'Chandler': 775,\n",
       " 'intelligent': 776,\n",
       " 'hedge': 777,\n",
       " 'DAYS': 778,\n",
       " 'doesnt': 779,\n",
       " 'Must': 780,\n",
       " '_Stokoe': 781,\n",
       " 'were-Wookiee': 782,\n",
       " 'workdays': 783,\n",
       " 'btween': 784,\n",
       " 'westlife': 785,\n",
       " '024': 786,\n",
       " 'HOMEWORK': 787,\n",
       " 'stranded': 788,\n",
       " '#bea': 789,\n",
       " 'hectic': 790,\n",
       " 'Nero': 791,\n",
       " 'reading': 792,\n",
       " 'Hurdle': 793,\n",
       " 'Fused': 794,\n",
       " 'Kyneton': 795,\n",
       " '#Evernote': 796,\n",
       " 'mel': 797,\n",
       " 'cOuld': 798,\n",
       " 'nott': 799,\n",
       " 'summy': 800,\n",
       " 'thinkin': 801,\n",
       " 'Pulaski': 802,\n",
       " 'adtï': 803,\n",
       " 'maxin': 804,\n",
       " 'tutorials': 805,\n",
       " 'see': 806,\n",
       " 'Gucci': 807,\n",
       " 'Treviso': 808,\n",
       " 'enuff': 809,\n",
       " 'LLLOOOVVVEEE': 810,\n",
       " 'loooove': 811,\n",
       " 'Alexxx': 812,\n",
       " 'itch': 813,\n",
       " 'images': 814,\n",
       " 'holiday.then': 815,\n",
       " 'ubertwitter': 816,\n",
       " 'COURSE': 817,\n",
       " 'wiggity': 818,\n",
       " 'Backup': 819,\n",
       " '½nadaï': 820,\n",
       " 'Hurry': 821,\n",
       " '½You': 822,\n",
       " 'cannae': 823,\n",
       " 'eithah': 824,\n",
       " 'cara': 825,\n",
       " 'hospice': 826,\n",
       " '_Atticus': 827,\n",
       " 'Dam': 828,\n",
       " 'family': 829,\n",
       " 'FELLOW': 830,\n",
       " 'funchal': 831,\n",
       " 'mirror': 832,\n",
       " 'Bugsssss': 833,\n",
       " 'notifications': 834,\n",
       " 'Dump': 835,\n",
       " 'Widow': 836,\n",
       " 'graduates': 837,\n",
       " 'Sebastian': 838,\n",
       " 'Rush': 839,\n",
       " 'sak': 840,\n",
       " 'lifes': 841,\n",
       " 'fantasy': 842,\n",
       " 'Survivor': 843,\n",
       " 'WACKY': 844,\n",
       " 'withdrawal': 845,\n",
       " 'recipient': 846,\n",
       " 'it.it': 847,\n",
       " 'ext': 848,\n",
       " 'canada': 849,\n",
       " '@_Glitter_': 850,\n",
       " 'runnin': 851,\n",
       " 'lab': 852,\n",
       " 'Chance': 853,\n",
       " 'coach': 854,\n",
       " 'sped': 855,\n",
       " 'liu': 856,\n",
       " 'LebrOn': 857,\n",
       " 'cramps': 858,\n",
       " 'southpark': 859,\n",
       " 'devon': 860,\n",
       " 'southend': 861,\n",
       " 'garbage': 862,\n",
       " 'Practice': 863,\n",
       " 'enjoy': 864,\n",
       " 'He': 865,\n",
       " '_double': 866,\n",
       " 'When': 867,\n",
       " '40': 868,\n",
       " 'bttr': 869,\n",
       " 'intern': 870,\n",
       " 'Zeke': 871,\n",
       " 'paracetamol': 872,\n",
       " 'hence': 873,\n",
       " 'regards': 874,\n",
       " 'youth': 875,\n",
       " 'Gud': 876,\n",
       " 'overnight': 877,\n",
       " 'felted': 878,\n",
       " 'lova': 879,\n",
       " 'shocked': 880,\n",
       " 'professional': 881,\n",
       " 'jetway': 882,\n",
       " 'Jordie': 883,\n",
       " 'Floor': 884,\n",
       " '#agile': 885,\n",
       " 'Foolish': 886,\n",
       " 'Blowout': 887,\n",
       " 'HOT': 888,\n",
       " 'over-the-top': 889,\n",
       " 'hungraaaaaaaaay': 890,\n",
       " \"people'-i\": 891,\n",
       " 'aerobars': 892,\n",
       " '_Crow': 893,\n",
       " 'YO': 894,\n",
       " 'http://andshehopes.blogspot.com/2009/05/kewpie.html': 895,\n",
       " 'suppoort': 896,\n",
       " '6:44': 897,\n",
       " 'terrific': 898,\n",
       " 'rebonded': 899,\n",
       " 'Here': 900,\n",
       " 'miserably': 901,\n",
       " 'chickened': 902,\n",
       " 'grader': 903,\n",
       " 'Yeahne': 904,\n",
       " 'Sgt': 905,\n",
       " 'Stress': 906,\n",
       " 'THURSTAG': 907,\n",
       " 'degr': 908,\n",
       " 'alredy': 909,\n",
       " 'applies': 910,\n",
       " 'tak': 911,\n",
       " 'johnn': 912,\n",
       " 'Same': 913,\n",
       " 'unzela': 914,\n",
       " 'Masson': 915,\n",
       " 'FTW': 916,\n",
       " 'threshold': 917,\n",
       " '2stop': 918,\n",
       " 'jordan': 919,\n",
       " 'http://tinysong.com/36pz': 920,\n",
       " 'Shows': 921,\n",
       " 'http://plurk.com/p/svm0w': 922,\n",
       " 'favourtie': 923,\n",
       " 'hulu': 924,\n",
       " 'asian': 925,\n",
       " 'sign': 926,\n",
       " '5/16': 927,\n",
       " 'Pre': 928,\n",
       " 'easports': 929,\n",
       " '½guez': 930,\n",
       " 'adjustment': 931,\n",
       " 'raspberry-Laced': 932,\n",
       " 'cameron': 933,\n",
       " 'Put': 934,\n",
       " 'anxious': 935,\n",
       " 'mumm': 936,\n",
       " 'circl': 937,\n",
       " 'magento': 938,\n",
       " 'http://plurk.com/p/x2k1z': 939,\n",
       " 'newt': 940,\n",
       " 'ly': 941,\n",
       " 'teetotaler': 942,\n",
       " 'fruity': 943,\n",
       " 'jacked': 944,\n",
       " 'dongle': 945,\n",
       " 'Ju': 946,\n",
       " '_day26': 947,\n",
       " 'yawn': 948,\n",
       " 'Ugh': 949,\n",
       " 'v': 950,\n",
       " 'http://www.thesixthaxis.com/staff/': 951,\n",
       " 'replace': 952,\n",
       " 'webcast': 953,\n",
       " 'g1': 954,\n",
       " 'Surprisingly': 955,\n",
       " ':': 956,\n",
       " '>': 957,\n",
       " 'belly': 958,\n",
       " 'mourners': 959,\n",
       " 'sunglasses': 960,\n",
       " 'orignal': 961,\n",
       " 'Chaperoning': 962,\n",
       " 'humans': 963,\n",
       " 'python': 964,\n",
       " 'contributing': 965,\n",
       " 'MLB': 966,\n",
       " '#Sanctuary': 967,\n",
       " 'migraine': 968,\n",
       " 'slowdown': 969,\n",
       " 'YEE': 970,\n",
       " 'yoou': 971,\n",
       " 'Hospital': 972,\n",
       " 'Crissy': 973,\n",
       " 'Tree': 974,\n",
       " 'w.bseresults.net': 975,\n",
       " 'manage': 976,\n",
       " 'matters': 977,\n",
       " 'jacksonville': 978,\n",
       " 'twiter': 979,\n",
       " 'wheel': 980,\n",
       " 'tuna': 981,\n",
       " 'bootleg': 982,\n",
       " 'photoblog': 983,\n",
       " 'findin': 984,\n",
       " 'sweetpea': 985,\n",
       " 'reservation': 986,\n",
       " 'Tuesdays': 987,\n",
       " 'relay': 988,\n",
       " 'friendship': 989,\n",
       " 'ups': 990,\n",
       " 'bid': 991,\n",
       " 'Meat': 992,\n",
       " '#whatshappening': 993,\n",
       " '>;(': 994,\n",
       " 'background': 995,\n",
       " 'ESTK': 996,\n",
       " 'Chrisette': 997,\n",
       " 'koi': 998,\n",
       " 'Tip': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'Y': 1, 'PAD': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [\"O\", \"Y\", \"PAD\"]\n",
    "tag2idx = {t:i for i,t in enumerate(tags)}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w] for w in s] for s in xt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [[tag2idx[t] for t in s] for s in yt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2517,\n",
       " 12138,\n",
       " 7847,\n",
       " 7847,\n",
       " 7847,\n",
       " 27617,\n",
       " 13108,\n",
       " 27770,\n",
       " 20137,\n",
       " 10169,\n",
       " 20044,\n",
       " 28399,\n",
       " 19906,\n",
       " 483,\n",
       " 1306,\n",
       " 8381,\n",
       " 9193,\n",
       " 1868,\n",
       " 19062]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for a in xt:\n",
    "    if(max_len < len(a)):\n",
    "        max_len = len(a)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=len(_words) -1)\n",
    "Y = pad_sequences(maxlen=max_len, sequences=Y, padding=\"post\", value=tag2idx[\"PAD\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2517, 12138,  7847,  7847,  7847, 27617, 13108, 27770, 20137,\n",
       "       10169, 20044, 28399, 19906,   483,  1306,  8381,  9193,  1868,\n",
       "       19062, 34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207,\n",
       "       34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207,\n",
       "       34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207,\n",
       "       34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207,\n",
       "       34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207, 34207,\n",
       "       34207, 34207, 34207], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_ = [\"neutral\", \"negative\", \"positive\"]\n",
    "sent2idx = {sen: i for i, sen in enumerate(sentiment_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neutral': 0, 'negative': 1, 'positive': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 1, 0, 2, 0, 0, 2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = [sent2idx[w] for w in sentiment]\n",
    "sentiment[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = np_utils.to_categorical(sentiment, num_classes=3)\n",
    "sentiment[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([ np_utils.to_categorical(i,num_classes=3) for i in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27480, 66), (27480, 3), (27480, 66, 3))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X1.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf2crf in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (0.1.5)\n",
      "Requirement already satisfied: tensorflow-addons>=0.8.2 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tf2crf) (0.10.0)\n",
      "Requirement already satisfied: tensorflow>=2.1.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tf2crf) (2.2.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow-addons>=0.8.2->tf2crf) (2.7.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (0.33.6)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.11.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (3.11.4)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (2.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (0.1.8)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (0.3.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.27.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.17.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (0.9.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (2.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorflow>=2.1.0->tf2crf) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow>=2.1.0->tf2crf) (41.4.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (1.6.0.post3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (0.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (2.22.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (1.11.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (1.3.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (1.24.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (4.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.1.0->tf2crf) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf2crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow_addons.text import crf\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, Dense, RepeatVector, TimeDistributed, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "from tf2crf import CRF\n",
    "input1 = Input(shape=(3,))\n",
    "fe1 = Dense(128, activation='relu')(input1)\n",
    "fe2 = RepeatVector(max_len)(fe1)\n",
    "fe3 = TimeDistributed(Dense(256, activation='relu'))(fe2)\n",
    "\n",
    "input2 = Input(shape=(max_len,))\n",
    "se1 = Embedding(len(_words),256, mask_zero=False, input_length=max_len)(input2)\n",
    "se2 =LSTM(128, return_sequences=True, recurrent_dropout=0.01)(se1)\n",
    "se3 = Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.01))(se2)\n",
    "\n",
    "# decoder1 = tf.keras.layers.Add()(se3, fe3])#add([se3, fe3])\n",
    "decoder1 = tf.keras.layers.Add()([se3, fe3])\n",
    "output1 = TimeDistributed((Dense(128, activation= 'relu')))(decoder1)\n",
    "output = TimeDistributed((Dense(64, activation= 'relu')))(output1)\n",
    "# crf_ = CRF(len(tags))\n",
    "# out = crf_(output)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 66)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 66, 256)      8757248     input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          512         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  (None, 66, 128)      197120      embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_7 (RepeatVector)  (None, 66, 128)      0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 66, 256)      263168      lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, 66, 256)      33024       repeat_vector_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 66, 256)      0           bidirectional_6[0][0]            \n",
      "                                                                 time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, 66, 128)      32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_19 (TimeDistri (None, 66, 64)       8256        time_distributed_18[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 9,292,224\n",
      "Trainable params: 9,292,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model( [input1, input2],  output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=crf_.loss, metrics=[crf_.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Incompatible shapes: [128,66] vs. [128]\n\t [[node Equal (defined at /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages/tf2crf/crf.py:91) ]] [Op:__inference_train_function_22225]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Equal:\n ArgMax (defined at /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages/tf2crf/crf.py:82)\t\n ArgMax_2 (defined at /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages/tf2crf/crf.py:88)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-02129cc95114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m early = tf.keras.callbacks.EarlyStopping(\n\u001b[1;32m      5\u001b[0m     monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Incompatible shapes: [128,66] vs. [128]\n\t [[node Equal (defined at /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages/tf2crf/crf.py:91) ]] [Op:__inference_train_function_22225]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Equal:\n ArgMax (defined at /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages/tf2crf/crf.py:82)\t\n ArgMax_2 (defined at /home/dlgpu-aus/anaconda3/envs/nlp/lib/python3.7/site-packages/tf2crf/crf.py:88)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "filepath = \"checkpoints\"\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto')\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n",
    "hist = model.fit(x=[X1,X], y = y, batch_size=128 , epochs=10, callbacks=[callback, early], validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
